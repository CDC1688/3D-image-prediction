# -*- coding: utf-8 -*-
"""2.Tencent_Lettuce_augment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l0nDjdGfcugjgdWcC3grJqO5ToO-9crq
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd

import tensorflow as tf, tensorflow.keras.backend as K
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Model
from tensorflow.keras import optimizers
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array

import os

import json
import glob
import cv2
import matplotlib.pyplot as plt
# %matplotlib inline

# Load the Drive helper and mount
from google.colab import drive

# This will prompt for authorization.
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/My Drive/tencent/'
path_img='/content/drive/My Drive/tencent/img/*.jpg'
path='/content/drive/My Drive/tencent/GroundTruth.json'

def pre_process_y(path):
    with open(path,'r') as f:
        data = json.loads(f.read())
    
    Image_list = list(data["Measurements"].keys())
    Field_list=list(data["Measurements"]["Image27"].keys())
    
    df2=[]
    for item in Field_list:
        df=[]    
        for img in Image_list:
            a=data["Measurements"][img][item]
            df.append(a)
        array=np.array(df)
        df2.append(array)
    
    df3=np.array(df2)    
    df=np.transpose(df3)
    data_out=pd.DataFrame(df,columns=['Variety', 'RGBImage', 'DebthInformation','FreshWeightShoot','DryWeightShoot',
                                'Height','Diameter','LeafArea'])
    return data_out

data_set =pre_process_y(path)
print(data_set)
data_set.columns
y_all=pd.DataFrame(data_set[['FreshWeightShoot','DryWeightShoot','Height','Diameter','LeafArea']])

#======CROP IMAGE TO GET RID OF UNECCESARY INTERRUPTION 
#================DO NOT RUN THIS CELL===================================
path_img='img/*.png'
def pre_process_crop(path_img):
  filenames = glob.glob(path_img)
  print(filenames)

  for i in filenames:
    img =cv2.imread(i, 1)
    crop_img = img[150:980, 600:1600]
    cv2.imwrite(i, crop_img) 

#pre_process_crop(path_img)   -----ONLY RUN THIS ONCE!!!!!

#=============================DO NOT RUN THIS CELL=====================

"""from PIL import Image
def myFunc(image):
    return cv2.cvtColor(image,cv2.COLOR_RGB2HSV)"""

path_img='img/*.png'
filenames = glob.glob(path_img)

datagen=ImageDataGenerator(
    rotation_range=180,
    width_shift_range=0.1,
    height_shift_range=0.1,
    brightness_range=[0.7, 1.5],
    rescale=1./255,
    #shear_range=0.2,  stable camera , not shear range
    #zoom_range= [0.8, 1.2],   don't impact size
    horizontal_flip=True,
    vertical_flip = True,
    fill_mode='nearest')

for i in filenames:
  #f=filenames[i]
  img_name=i.split("/")[1].split(".")[0]
  img=load_img(i)
  x=img_to_array(img)
  x = x.reshape((1,) + x.shape)  #reshape to add 1 dimention

#=======Be aware of overall number of different pic in a batch can impact performance 
  count=0
  for batch in datagen.flow(x, batch_size=1,
                            save_to_dir='aug2/', save_prefix=img_name, save_format='jpeg'):
      count += 1
      if count >= 2:
          break  # otherwise the generator would loop indefinitely