# -*- coding: utf-8 -*-
"""3.Tencent_Lettuce_preprocess.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vBF58XVLk2NC0ZBdo-uboG69djk7Lgue
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd

import tensorflow as tf, tensorflow.keras.backend as K
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Model
from tensorflow.keras import optimizers
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array

import os

import json
import glob
import cv2
import matplotlib.pyplot as plt
# %matplotlib inline

# Load the Drive helper and mount
from google.colab import drive

# This will prompt for authorization.
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/My Drive/tencent/'
#path_img='/content/drive/My Drive/tencent/img/*.jpg'
path='/content/drive/My Drive/tencent/GroundTruth_Final.json'

def pre_process_y(path):
    with open(path,'r') as f:
        data = json.loads(f.read())
    
    Image_list = list(data["Measurements"].keys())
    Field_list=list(data["Measurements"]["Image27"].keys())
    
    df2=[]
    for item in Field_list:
        df=[]    
        for img in Image_list:
            a=data["Measurements"][img][item]
            df.append(a)
        array=np.array(df)
        df2.append(array)
    
    df3=np.array(df2)    
    df=np.transpose(df3)
    data_out=pd.DataFrame(df,columns=['Variety', 'RGBImage', 'DebthInformation','FreshWeightShoot','DryWeightShoot',
                                'Height','Diameter','LeafArea'])
    return data_out

data_set =pre_process_y(path)
print(data_set)
data_set.columns
y_all=pd.DataFrame(data_set[['FreshWeightShoot','DryWeightShoot','Height','Diameter','LeafArea']])

#=====assign label for augmented img 
#=====================DO NO RUN THIS CELL ============================
aug_path='aug2/*.jpeg'
new_files = glob.glob(aug_path)

PRINT(LEN)
#=====get their corresponding img 
img_list=[]
for i in new_files:
  a=i.split("/")[1]
  #print(a)
  a1=a.split(".")
  #print(a1[0])
  a2=a1[0].split("_")
  a3=a2[0]+"_"+a2[1]
  img_list.append(a3)
print(img_list)

def pre_list(img_list,new_files):
  img_list1=np.array(img_list)
  img_list1=img_list1.reshape(img_list1.shape+(1,))
  #print(img_list1.shape)
  new_files1=np.array(new_files)
  new_files1=new_files1.reshape(new_files1.shape+(1,))
  #print(new_files1.shape)
  result=np.concatenate((img_list1, new_files1), axis=1)
  result_df=pd.DataFrame(result)
  result_df.rename(columns={0: "x",1: "img_location"},inplace=True)

  return result_df

result_df=pre_list(img_list,new_files)
data_set =pre_process_y(path)
print(data_set)
print(len(result_df))


def format_new_aug_label(data_set,result_df):
  data_set['x']=data_set['RGBImage'].str.split(pat='.',expand=True)[0]
  data_all=pd.merge(result_df,data_set,how='left',on='x')
  data_all=data_all.drop(['RGBImage'],axis=1)  #=====drop old real img name 
  data_all['RGBImage']=pd.DataFrame(data_all['img_location'].str.split(pat="/",expand=True)[1])   #====replace with augmented img name
  data_final=data_all.drop(['img_location','x'],axis=1)  #=======map old format of 8 columns
  print(data_final.columns)
  return data_final

data_final=format_new_aug_label(data_set,result_df)
data_set1 =pre_process_y(path)
data_all=data_final.append(data_set1)
data_all.to_excel('aug_new_all.xlsx')